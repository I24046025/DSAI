{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 100000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789+- '\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '+',\n",
       " 2: '-',\n",
       " 3: '0',\n",
       " 4: '1',\n",
       " 5: '2',\n",
       " 6: '3',\n",
       " 7: '4',\n",
       " 8: '5',\n",
       " 9: '6',\n",
       " 10: '7',\n",
       " 11: '8',\n",
       " 12: '9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(opTypes):\n",
    "    questions = []\n",
    "    expected = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(questions) < TRAINING_SIZE:\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        if len(opTypes) > 1:\n",
    "            opType = np.random.choice(list(opTypes))\n",
    "        else:\n",
    "            opType = opTypes\n",
    "        key = tuple(sorted((a, b))) + tuple(opTypes)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        q = '{}{}{}'.format(a,opType,b)\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        if opType == '+':\n",
    "            ans = str(a + b)\n",
    "        else:\n",
    "            ans = str(a - b)\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        if REVERSE:\n",
    "            query = query[::-1]\n",
    "        questions.append(query)\n",
    "        expected.append(ans)\n",
    "    print('Done!')\n",
    "    print(questions[:5], expected[:5])\n",
    "    return questions, expected\n",
    "    \n",
    "# questions, expected = generateData('-+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(questions, expected):\n",
    "    print('Vectorization...')\n",
    "    x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(expected), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(questions):\n",
    "        x[i] = ctable.encode(sentence, MAXLEN)\n",
    "    for i, sentence in enumerate(expected):\n",
    "        y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "    print('Done!')\n",
    "    return x, y\n",
    "\n",
    "# x, y = vectorization(questions, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, train_size):\n",
    "    indices = np.arange(len(y))\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # train_test_split\n",
    "    train_x = x[:train_size]\n",
    "    train_y = y[:train_size]\n",
    "    test_x = x[train_size:]\n",
    "    test_y = y[train_size:]\n",
    "\n",
    "    split_at = len(train_x) - len(train_x) // 10\n",
    "    (x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "    (y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "    \n",
    "    print('Training Data:')\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    print('Validation Data:')\n",
    "    print(x_val.shape)\n",
    "    print(y_val.shape)\n",
    "\n",
    "    print('Testing Data:')\n",
    "    print(test_x.shape)\n",
    "    print(test_y.shape)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, test_x, test_y\n",
    "\n",
    "# x_train, y_train, x_val, y_val, test_x, test_y = train_test_split(x, y, 40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "    model.add(layers.RepeatVector(DIGITS + 1))\n",
    "    for i in range(LAYERS):\n",
    "        model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# adder = buildModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, x_train, y_train, x_val, y_val, test_x, test_y):\n",
    "    acc_record = []\n",
    "    for iteration in range(100):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=1,\n",
    "                  validation_data=(x_val, y_val))\n",
    "        acc = evaluate(model, test_x, test_y)\n",
    "        acc_record.append(acc)\n",
    "        if acc > 0.95:\n",
    "            break\n",
    "    return model, acc_record\n",
    "\n",
    "# adder = trainModel(adder, x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y):\n",
    "    num_corrects = 0\n",
    "    prediction = model.predict_classes(test_x)\n",
    "    for i in range(len(prediction)):\n",
    "        ans = ctable.decode(test_y[i])\n",
    "        guess = ctable.decode(prediction[i], calc_argmax=False)\n",
    "        if ans == guess:\n",
    "            num_corrects += 1\n",
    "    print(\"Accuracy: {}\".format(num_corrects / len(prediction)))\n",
    "    return float(num_corrects / len(prediction))\n",
    "    \n",
    "# evaluate(adder, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(record):\n",
    "    plt.plot(record)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Adder\n",
    "* Operator: '+'\n",
    "* Training Data: 18000\n",
    "* Validation Data: 2000\n",
    "* Testing Data: 80000\n",
    "* Digits: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Done!\n",
      "['969+8  ', '5+5    ', '9+19   ', '37+1   ', '28+4   '] ['977 ', '10  ', '28  ', '38  ', '32  ']\n",
      "Vectorization...\n",
      "Done!\n",
      "Training Data:\n",
      "(18000, 7, 13)\n",
      "(18000, 4, 13)\n",
      "Validation Data:\n",
      "(2000, 7, 13)\n",
      "(2000, 4, 13)\n",
      "Testing Data:\n",
      "(80000, 7, 13)\n",
      "(80000, 4, 13)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 128)               72704     \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 4, 13)             1677      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 13)             0         \n",
      "=================================================================\n",
      "Total params: 205,965\n",
      "Trainable params: 205,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 7s 367us/step - loss: 2.0458 - acc: 0.2864 - val_loss: 1.8836 - val_acc: 0.3225\n",
      "Accuracy: 0.0006375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 202us/step - loss: 1.8672 - acc: 0.3260 - val_loss: 1.8520 - val_acc: 0.3327\n",
      "Accuracy: 0.0002125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 210us/step - loss: 1.8266 - acc: 0.3286 - val_loss: 1.8034 - val_acc: 0.3320\n",
      "Accuracy: 0.0007625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 231us/step - loss: 1.7712 - acc: 0.3436 - val_loss: 1.7442 - val_acc: 0.3518\n",
      "Accuracy: 0.0014625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 1.6973 - acc: 0.3648 - val_loss: 1.6813 - val_acc: 0.3686\n",
      "Accuracy: 0.0029375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 244us/step - loss: 1.6375 - acc: 0.3857 - val_loss: 1.6205 - val_acc: 0.3818\n",
      "Accuracy: 0.0035375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 237us/step - loss: 1.5842 - acc: 0.4043 - val_loss: 1.5612 - val_acc: 0.4129\n",
      "Accuracy: 0.0050125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 1.5436 - acc: 0.4205 - val_loss: 1.5170 - val_acc: 0.4245\n",
      "Accuracy: 0.006125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 1.4898 - acc: 0.4401 - val_loss: 1.4844 - val_acc: 0.4327\n",
      "Accuracy: 0.0075375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 196us/step - loss: 1.4462 - acc: 0.4560 - val_loss: 1.4261 - val_acc: 0.4581\n",
      "Accuracy: 0.0105625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 1.4011 - acc: 0.4744 - val_loss: 1.3841 - val_acc: 0.4812\n",
      "Accuracy: 0.0117625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 1.3590 - acc: 0.4939 - val_loss: 1.3421 - val_acc: 0.5033\n",
      "Accuracy: 0.0163375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 1.3253 - acc: 0.5066 - val_loss: 1.3667 - val_acc: 0.4810\n",
      "Accuracy: 0.0155125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 1.2899 - acc: 0.5222 - val_loss: 1.2803 - val_acc: 0.5232\n",
      "Accuracy: 0.0235875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 210us/step - loss: 1.2551 - acc: 0.5353 - val_loss: 1.2542 - val_acc: 0.5325\n",
      "Accuracy: 0.0247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 202us/step - loss: 1.2158 - acc: 0.5519 - val_loss: 1.2215 - val_acc: 0.5411\n",
      "Accuracy: 0.0295\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 195us/step - loss: 1.1833 - acc: 0.5629 - val_loss: 1.1839 - val_acc: 0.5570\n",
      "Accuracy: 0.0347375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 195us/step - loss: 1.1492 - acc: 0.5751 - val_loss: 1.1543 - val_acc: 0.5649\n",
      "Accuracy: 0.033325\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.1243 - acc: 0.5832 - val_loss: 1.1253 - val_acc: 0.5747\n",
      "Accuracy: 0.040225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 1.0812 - acc: 0.6003 - val_loss: 1.0940 - val_acc: 0.5876\n",
      "Accuracy: 0.0461375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 1.0508 - acc: 0.6096 - val_loss: 1.0521 - val_acc: 0.6069\n",
      "Accuracy: 0.0507375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 198us/step - loss: 1.0126 - acc: 0.6263 - val_loss: 1.0274 - val_acc: 0.6144\n",
      "Accuracy: 0.0625125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 214us/step - loss: 0.9741 - acc: 0.6395 - val_loss: 0.9708 - val_acc: 0.6326\n",
      "Accuracy: 0.084375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 202us/step - loss: 0.9214 - acc: 0.6614 - val_loss: 0.9314 - val_acc: 0.6433\n",
      "Accuracy: 0.104475\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 202us/step - loss: 0.8601 - acc: 0.6823 - val_loss: 0.8608 - val_acc: 0.6734\n",
      "Accuracy: 0.1461625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 4s 197us/step - loss: 0.7809 - acc: 0.7141 - val_loss: 0.7757 - val_acc: 0.7121\n",
      "Accuracy: 0.1994\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 213us/step - loss: 0.6964 - acc: 0.7473 - val_loss: 0.6824 - val_acc: 0.7429\n",
      "Accuracy: 0.275075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 201us/step - loss: 0.6169 - acc: 0.7842 - val_loss: 0.6053 - val_acc: 0.7785\n",
      "Accuracy: 0.357825\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.5415 - acc: 0.8213 - val_loss: 0.5311 - val_acc: 0.8248\n",
      "Accuracy: 0.450375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 198us/step - loss: 0.4865 - acc: 0.8480 - val_loss: 0.5007 - val_acc: 0.8311\n",
      "Accuracy: 0.4795875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 283us/step - loss: 0.4370 - acc: 0.8703 - val_loss: 0.4287 - val_acc: 0.8681\n",
      "Accuracy: 0.581475\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 305us/step - loss: 0.3878 - acc: 0.8950 - val_loss: 0.4037 - val_acc: 0.8839\n",
      "Accuracy: 0.6042\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 309us/step - loss: 0.3562 - acc: 0.9076 - val_loss: 0.3568 - val_acc: 0.9011\n",
      "Accuracy: 0.662725\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 0.3117 - acc: 0.9269 - val_loss: 0.3283 - val_acc: 0.9167\n",
      "Accuracy: 0.705175\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 0.2898 - acc: 0.9327 - val_loss: 0.3063 - val_acc: 0.9191\n",
      "Accuracy: 0.726475\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 0.2571 - acc: 0.9458 - val_loss: 0.2857 - val_acc: 0.9203\n",
      "Accuracy: 0.7390125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 279us/step - loss: 0.2349 - acc: 0.9509 - val_loss: 0.2676 - val_acc: 0.9320\n",
      "Accuracy: 0.762525\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 331us/step - loss: 0.2108 - acc: 0.9590 - val_loss: 0.2400 - val_acc: 0.9392\n",
      "Accuracy: 0.78365\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 322us/step - loss: 0.2032 - acc: 0.9576 - val_loss: 0.2390 - val_acc: 0.9347\n",
      "Accuracy: 0.783875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 309us/step - loss: 0.1850 - acc: 0.9632 - val_loss: 0.2124 - val_acc: 0.9463\n",
      "Accuracy: 0.8103625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 286us/step - loss: 0.1637 - acc: 0.9706 - val_loss: 0.2131 - val_acc: 0.9414\n",
      "Accuracy: 0.800425\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 284us/step - loss: 0.1522 - acc: 0.9717 - val_loss: 0.1780 - val_acc: 0.9545\n",
      "Accuracy: 0.8356375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 284us/step - loss: 0.1460 - acc: 0.9720 - val_loss: 0.2373 - val_acc: 0.9269\n",
      "Accuracy: 0.7476375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 283us/step - loss: 0.1491 - acc: 0.9677 - val_loss: 0.1525 - val_acc: 0.9644\n",
      "Accuracy: 0.8761\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 316us/step - loss: 0.1191 - acc: 0.9802 - val_loss: 0.1746 - val_acc: 0.9498\n",
      "Accuracy: 0.833425\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 324us/step - loss: 0.1215 - acc: 0.9767 - val_loss: 0.1456 - val_acc: 0.9625\n",
      "Accuracy: 0.8616875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 303us/step - loss: 0.1014 - acc: 0.9841 - val_loss: 0.1331 - val_acc: 0.9660\n",
      "Accuracy: 0.86925\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 288us/step - loss: 0.0901 - acc: 0.9871 - val_loss: 0.1239 - val_acc: 0.9680\n",
      "Accuracy: 0.891325\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 289us/step - loss: 0.0899 - acc: 0.9849 - val_loss: 0.1081 - val_acc: 0.9733\n",
      "Accuracy: 0.9004875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 294us/step - loss: 0.0806 - acc: 0.9877 - val_loss: 0.1078 - val_acc: 0.9744\n",
      "Accuracy: 0.9109875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 289us/step - loss: 0.1082 - acc: 0.9729 - val_loss: 0.1601 - val_acc: 0.9497\n",
      "Accuracy: 0.8020375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 324us/step - loss: 0.0948 - acc: 0.9792 - val_loss: 0.1059 - val_acc: 0.9719\n",
      "Accuracy: 0.8934\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 332us/step - loss: 0.0638 - acc: 0.9913 - val_loss: 0.0931 - val_acc: 0.9780\n",
      "Accuracy: 0.9196375\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 335us/step - loss: 0.0561 - acc: 0.9932 - val_loss: 0.0813 - val_acc: 0.9808\n",
      "Accuracy: 0.927325\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 294us/step - loss: 0.0523 - acc: 0.9941 - val_loss: 0.0805 - val_acc: 0.9780\n",
      "Accuracy: 0.9272875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 300us/step - loss: 0.0505 - acc: 0.9938 - val_loss: 0.0757 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93035\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 0.0496 - acc: 0.9929 - val_loss: 0.2673 - val_acc: 0.9260\n",
      "Accuracy: 0.7738\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 237us/step - loss: 0.0973 - acc: 0.9720 - val_loss: 0.0793 - val_acc: 0.9789\n",
      "Accuracy: 0.9235625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 252us/step - loss: 0.0432 - acc: 0.9947 - val_loss: 0.0735 - val_acc: 0.9807\n",
      "Accuracy: 0.9288875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 301us/step - loss: 0.0390 - acc: 0.9953 - val_loss: 0.0674 - val_acc: 0.9820\n",
      "Accuracy: 0.941025\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 282us/step - loss: 0.0346 - acc: 0.9966 - val_loss: 0.0605 - val_acc: 0.9852\n",
      "Accuracy: 0.943975\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 280us/step - loss: 0.0339 - acc: 0.9963 - val_loss: 0.0678 - val_acc: 0.9812\n",
      "Accuracy: 0.9336125\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 275us/step - loss: 0.0621 - acc: 0.9856 - val_loss: 0.3758 - val_acc: 0.8790\n",
      "Accuracy: 0.61795\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 283us/step - loss: 0.0899 - acc: 0.9728 - val_loss: 0.0751 - val_acc: 0.9784\n",
      "Accuracy: 0.921525\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 5s 295us/step - loss: 0.0318 - acc: 0.9962 - val_loss: 0.0600 - val_acc: 0.9860\n",
      "Accuracy: 0.9434625\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 65\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 6s 312us/step - loss: 0.0274 - acc: 0.9974 - val_loss: 0.0531 - val_acc: 0.9868\n",
      "Accuracy: 0.94565\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 66\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 0.0255 - acc: 0.9976 - val_loss: 0.0558 - val_acc: 0.9846\n",
      "Accuracy: 0.941425\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 67\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 233us/step - loss: 0.0244 - acc: 0.9977 - val_loss: 0.0542 - val_acc: 0.9850\n",
      "Accuracy: 0.9471875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 68\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 0.0257 - acc: 0.9965 - val_loss: 0.0548 - val_acc: 0.9856\n",
      "Accuracy: 0.9455875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 69\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 0.0223 - acc: 0.9978 - val_loss: 0.0509 - val_acc: 0.9873\n",
      "Accuracy: 0.951375\n",
      "Accuracy: 0.951375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opType = '+'\n",
    "trainSize = 20000\n",
    "questions, expected = generateData(opType)\n",
    "x, y = vectorization(questions, expected)\n",
    "x_train, y_train, x_val, y_val, test_x, test_y = train_test_split(x, y, trainSize)\n",
    "adder = buildModel()\n",
    "adder, acc_record = trainModel(adder, x_train, y_train, x_val, y_val, test_x, test_y)\n",
    "# evaluate(adder, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
